# ğŸš€ Projeto de DetecÃ§Ã£o de Gestos com MÃ£os usando YOLO âœ‹ğŸ¤–

Este projeto utiliza a rede neural YOLO (You Only Look Once) para detectar gestos feitos com as mÃ£os em imagens. O objetivo Ã© treinar o modelo YOLO para identificar e classificar diferentes gestos realizados com as mÃ£os, aplicando-o em uma base de dados de imagens de sinais manuais. O modelo pode ser usado em sistemas de reconhecimento de gestos em tempo real.

## ğŸ“‹ Funcionalidades

- **DetecÃ§Ã£o de Gestos Manuais**: Detecte gestos feitos com as mÃ£os em imagens estÃ¡ticas utilizando o modelo YOLO.
- **Modelo PrÃ©-Treinado**: Utiliza o modelo YOLOv5 prÃ©-treinado para detectar objetos e pode ser adaptado para detectar gestos manuais.
- **Treinamento Personalizado**: Possibilidade de treinar o modelo com sua prÃ³pria base de dados de gestos manuais.

## ğŸ—ƒ Base de Dados

Para este projeto, utilizamos a base de dados **Sign Language MNIST** como exemplo. Esta base contÃ©m imagens de gestos das letras do alfabeto em linguagem de sinais americana. A base Ã© simples e serve para fins de teste e demonstraÃ§Ã£o.

Alternativamente, vocÃª pode usar outras bases de dados como:

- **HAND GESTURE RECOGNITION DATABASE**: ContÃ©m gestos mais dinÃ¢micos e complexos.
- **Custom Data**: VocÃª pode criar sua prÃ³pria base de dados de gestos manuais e rotulÃ¡-la para o treinamento.

## ğŸ”§ Tecnologias

- **YOLO (You Only Look Once)**: Rede neural eficiente para detecÃ§Ã£o de objetos em tempo real.
- **OpenCV**: Biblioteca para manipulaÃ§Ã£o e exibiÃ§Ã£o de imagens.
- **PyTorch**: Framework utilizado para carregar e treinar o modelo YOLO.
- **LabelImg**: Ferramenta para rotulaÃ§Ã£o de dados (opcional).

## ğŸš€ Como Usar

### 1. Instalar DependÃªncias

Instale as dependÃªncias necessÃ¡rias usando o `pip`:

```bash
pip install opencv-python opencv-python-headless torch torchvision matplotlib
```

### 2. Carregar e Exibir Imagens

Carregue uma imagem e visualize o gesto manual:

```python
import torch
import torchvision
import cv2
import matplotlib.pyplot as plt

# Carregar uma imagem da base de dados
train_set = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)
img, label = train_set[0]
plt.imshow(img, cmap='gray')
plt.title(f'Label: {label}')
plt.show()
```

### 3. Detectar Gestos com YOLO

Carregue um modelo prÃ©-treinado YOLOv5 e faÃ§a a detecÃ§Ã£o de gestos em uma imagem.

```python
# Carregar o modelo YOLOv5 prÃ©-treinado
model = torch.hub.load('ultralytics/yolov5', 'yolov5s')

# Carregar uma imagem de gesto manual
img_path = 'path/to/hand_gesture_image.jpg'
img = cv2.imread(img_path)
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Realizar a detecÃ§Ã£o
results = model(img_rgb)

# Exibir a imagem com a caixa delimitadora
results.show()
```

### 4. Treinamento Personalizado

Se vocÃª tiver sua prÃ³pria base de dados de gestos, crie anotaÃ§Ãµes no formato YOLO e treine o modelo com o seguinte comando:

```bash
python train.py --data custom_data.yaml --cfg yolov5s.yaml --weights '' --batch-size 16 --img-size 640 --epochs 50
```

O arquivo `custom_data.yaml` deve conter o caminho para as imagens e as anotaÃ§Ãµes das classes de gestos.

## ğŸ—‚ Estrutura do Projeto

Aqui estÃ¡ a estrutura bÃ¡sica do diretÃ³rio:

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/          # Imagens de treinamento
â”‚   â”œâ”€â”€ test/           # Imagens de teste
â”‚   â””â”€â”€ annotations/    # Arquivos de anotaÃ§Ãµes (no formato YOLO)
â”œâ”€â”€ models/             # Arquivos do modelo treinado
â”œâ”€â”€ train.py            # Script para treinar o modelo
â”œâ”€â”€ detect.py           # Script para realizar a detecÃ§Ã£o de gestos
â”œâ”€â”€ README.md           # Este arquivo
â””â”€â”€ requirements.txt    # DependÃªncias do projeto
```

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes para o projeto sÃ£o **bem-vindas**! Sinta-se Ã  vontade para abrir **issues** ou enviar **pull requests** com melhorias, correÃ§Ãµes ou sugestÃµes. Vamos construir algo incrÃ­vel juntos! ğŸ’»

## ğŸ“œ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - consulte o arquivo [LICENSE](LICENSE) para mais detalhes. 

---

ğŸ‰ **Obrigado por contribuir ou utilizar este projeto!** ğŸ‰


### Melhorias com Emojis:
1. **CabeÃ§alhos e TÃ­tulos**: Emojis ajudam a destacar os principais tÃ³picos, como o uso do modelo YOLO, as funcionalidades e a licenÃ§a.
2. **Exemplos de CÃ³digo**: NÃ£o alterei o cÃ³digo, mas acrescentei emojis para tornÃ¡-lo mais fÃ¡cil de seguir visualmente.
3. **TÃ­tulos e SeÃ§Ãµes**: Emojis sÃ£o usados em seÃ§Ãµes como "Tecnologias", "Como Usar", "ContribuiÃ§Ãµes", etc., para tornar o arquivo mais atraente.
4. **ContribuiÃ§Ãµes e LicenÃ§a**: AdiÃ§Ã£o de emojis para engajar mais o usuÃ¡rio na ideia de colaboraÃ§Ã£o e para tornar o final do README mais positivo.

Esse formato torna o arquivo mais amigÃ¡vel e visualmente interessante! ğŸ˜„
